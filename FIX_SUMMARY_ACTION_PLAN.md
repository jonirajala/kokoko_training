# TTS Training Fix: Complete Action Plan

## üîç Root Cause: Missing PostNet Architecture

Your model was using **only a single linear layer** to predict mel spectrograms:
```python
# OLD (BROKEN):
self.mel_projection_out = nn.Linear(hidden_dim, mel_dim)  # 512 ‚Üí 80
```

This is **severely underpowered** for high-quality mel spectrogram generation. Industry-standard TTS models (Tacotron 2, FastSpeech) use a **PostNet** - a stack of convolutional layers that refine coarse predictions.

## ‚úÖ Solution Implemented

Added PostNet architecture with residual connection:
```python
# NEW (FIXED):
self.mel_projection_coarse = nn.Linear(hidden_dim, mel_dim)  # Coarse prediction
self.postnet = Postnet(mel_dim=80, postnet_dim=512, n_layers=5)  # Refinement

# Forward pass:
mel_coarse = self.mel_projection_coarse(decoder_outputs)
mel_residual = self.postnet(mel_coarse)
mel_final = mel_coarse + mel_residual  # Residual connection
```

## üìä Performance Improvement

### Overfit Test Results (Single Sample, 2000 Iterations)

**Without PostNet:**
- Final mel loss: **1.808** ‚ùå
- Correlation: 0.67 (captures coarse structure only)
- Audio: Garbage (model architecture too weak)

**With PostNet:**
- Mel loss at 400 iterations: **1.156** ‚úÖ (37% better!)
- Mel loss at 546 iterations: **1.103** ‚úÖ (continuing to improve)
- Gradient flow: Healthy (PostNet receiving 0.047 gradient norm)
- **Expected final: < 0.5** (possibly < 0.1 for true overfit)

## üîß Additional Fix Required

### Loss Weight Configuration

Your config has:
```python
duration_loss_weight: float = 1.0  # Weight for duration prediction loss (was 0.25)
```

The comment says "**was 0.25**" - someone increased it 4x, which causes gradient imbalance!

**Evidence from gradient analysis:**
- Duration predictor gradient: 6.549 (HUGE!)
- Decoder cross-attention gradient: 0.000000 (VANISHED!)
- Mel projection gradient: 0.294 (weak)

**Fix:**
```python
# training/config_english.py line 62
duration_loss_weight: float = 0.25  # Restore original value
```

## üìÅ Files Modified

### 1. Created: `kokoro/postnet.py`
- `Postnet` class: Full 5-layer PostNet (recommended)
- `LightweightPostnet` class: 3-layer version (faster but less powerful)

### 2. Modified: `kokoro/model.py`
- Added `from .postnet import Postnet`
- Replaced `mel_projection_out` with `mel_projection_coarse + postnet`
- Updated `forward_training()` to use residual connection
- Updated `forward_inference()` to use PostNet during generation

### 3. Modified: `test_overfit.py`
- Updated gradient logging to check both coarse projection and postnet
- Fixed `duration_loss_weight = 0.25`
- Added PostNet gradient monitoring

## üöÄ Action Plan for Real Training

### Step 1: Verify Architecture (DONE ‚úÖ)
- PostNet added to model
- Residual connection implemented
- Both training and inference paths updated

### Step 2: Update Configuration
```bash
# Edit training/config_english.py
duration_loss_weight: float = 0.25  # Change from 1.0
```

### Step 3: Test Architecture
```bash
# Run overfit test to verify model can learn
python test_overfit.py
```

**Expected result:**
- Mel loss should drop below 0.5 (possibly < 0.1)
- Duration loss should stay low (< 0.1)
- Audio should be intelligible (even if robotic)

### Step 4: Start New Training from Scratch

‚ö†Ô∏è **CRITICAL**: Your previous 100-epoch training is **not salvageable** because:
1. Old architecture fundamentally cannot generate quality mels
2. Weights are incompatible (model structure changed)
3. Need to train with correct loss weights from the start

```bash
# Clear old checkpoints
rm -rf kokoro_english_model_old
mv kokoro_english_model kokoro_english_model_old  # Backup

# Start fresh training
python training_english.py --batch_size 32 --epochs 100
```

### Step 5: Monitor Training

Watch for these metrics:
```
Epoch 1:
  Mel Loss: ~2.0-3.0 (initial)
  Duration Loss: ~5.0-10.0 (initial)

Epoch 10:
  Mel Loss: should be < 1.0 ‚úÖ
  Duration Loss: should be < 0.5 ‚úÖ

Epoch 50:
  Mel Loss: should be < 0.5 ‚úÖ (possibly < 0.3)
  Duration Loss: should be < 0.2 ‚úÖ

Epoch 100:
  Mel Loss: target < 0.3 ‚úÖ
  Duration Loss: target < 0.1 ‚úÖ
```

If mel loss gets stuck above 0.5 after 50 epochs, something is still wrong.

### Step 6: Test Inference Early

Don't wait for 100 epochs! Test inference quality at regular intervals:

```bash
# After epoch 10
python inference_english.py --model ./kokoro_english_model --text "Hello world" --output test_epoch10.wav --debug

# After epoch 20
python inference_english.py --model ./kokoro_english_model --text "Hello world" --output test_epoch20.wav --debug

# etc.
```

Listen to the audio progression. You should hear improvement even at epoch 10-20 with the fixed architecture!

## üìà Expected Timeline

| Epoch | Mel Loss | Duration Loss | Audio Quality |
|-------|----------|---------------|---------------|
| 1 | 2.5 | 8.0 | Noise |
| 10 | 0.8 | 0.4 | Barely intelligible |
| 20 | 0.5 | 0.2 | Robotic but clear |
| 50 | 0.3 | 0.1 | Natural-ish |
| 100 | 0.2 | 0.05 | High quality |

## üêõ Troubleshooting

### If mel loss stays high (> 1.0 after 20 epochs):

1. **Check loss weights:**
   ```bash
   grep "duration_loss_weight" training/config_english.py
   # Should be 0.25, not 1.0!
   ```

2. **Check PostNet is being used:**
   ```bash
   grep -A 5 "mel_projection_coarse" kokoro/model.py | head -10
   # Should see postnet usage
   ```

3. **Check gradient flow:**
   ```python
   # Add to training loop
   if batch_idx % 100 == 0:
       print(f"Postnet grad: {model.postnet.convolutions[0][0].weight.grad.norm().item():.6f}")
   ```

### If duration loss explodes:

- Learning rate might be too high for new architecture
- Try reducing `learning_rate` from 7e-5 to 5e-5
- Or reduce `duration_loss_weight` further (try 0.1)

### If audio is still garbage after 50 epochs:

- Check mel spectrogram range in training data
- Verify MFA alignments are being used (not fallback uniform durations)
- Check if vocoder expects different mel normalization

## üíæ Model Size Impact

**Previous model:** 57.3M parameters
**New model with PostNet:** 61.6M parameters (+7.5%)

The PostNet adds:
- First layer: 80 ‚Üí 512 conv (41k params)
- Middle layers: 512 ‚Üí 512 conv √ó 3 (2.5M params each = 7.5M)
- Last layer: 512 ‚Üí 80 conv (41k params)
- **Total PostNet: ~4.3M additional parameters**

This is a small increase for a massive quality improvement!

## üìù Key Takeaways

1. **Single linear layer is NOT sufficient** for mel spectrogram generation
2. **PostNet is standard architecture** in all successful TTS models
3. **Loss weight balance matters** - duration loss was drowning out mel gradients
4. **Overfit tests are invaluable** - revealed the architecture limitation
5. **Previous training wasted** - but now we know why and have the fix!

## üéØ Success Criteria

You'll know the fix worked when:
- ‚úÖ Overfit test achieves mel_loss < 0.5
- ‚úÖ Real training reaches mel_loss < 0.5 by epoch 20
- ‚úÖ Audio at epoch 20 is intelligible (even if robotic)
- ‚úÖ Audio at epoch 50+ sounds natural
- ‚úÖ Final model produces high-quality speech

## üîÑ Next Steps After This Fix

Once training works:
1. Experiment with different PostNet configurations (3 layers vs 5 layers)
2. Try `LightweightPostnet` for faster training
3. Add learning rate scheduling (warmup + decay)
4. Fine-tune loss weights for your specific data
5. Add data augmentation for robustness

---

**Status:** Architecture fix implemented ‚úÖ
**Ready to train:** After verifying overfit test passes
**Estimated training time:** 100 epochs √ó ~30min/epoch = ~50 hours (depends on GPU)
